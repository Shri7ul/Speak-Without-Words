# ğŸ–ï¸ Speak Without Words  
### Real-time Gesture â†’ Intent â†’ Visual Language

> A real-time computer vision system that allows humans to communicate **without speaking**, using hand gestures captured via webcam and translated into visual + voice feedback.

---

## ğŸš€ Inspiration
Many people cannot communicate verbally in critical situations â€” due to noise, disability, distance, or urgency.  
**Speak Without Words** explores how **hand gestures alone** can become a universal, fast, and intuitive communication layer.

---

## âœ¨ Features

### ğŸ§  Core
- Real-time hand detection using **OpenCV + MediaPipe**
- Gesture classification (rule-based, no heavy ML)
- Gesture smoothing (majority voting)
- Confidence scoring

### âœ‹ Supported Gestures
| Gesture | Meaning |
|------|------|
| Open Palm | â›” STOP |
| Fist | âœ‹ WAIT |
| Peace | ğŸ’™ CALM |
| Open Palm (High) | ğŸš¨ HELP |
| Both Palms | ğŸ™Œ HANDS UP |

---

### ğŸ” Secret Gesture Codes
- **UNDERSTOOD** â†’ `PEACE â†’ FIST â†’ OPEN PALM`
- **TEAM READY** â†’ `HANDS UP â†’ PEACE`

> These are detected using **temporal gesture sequences**, not single frames.

---

### ğŸ”Š Voice Feedback
- Browser-native **Text-to-Speech**
- Speaks detected intent (STOP, HELP, TEAM READY, etc.)
- Fully client-side (no audio files required)

*(Optional sound effect support included, commented in code)*

---

### ğŸ‹ï¸ Training Mode
- Practice gestures interactively
- Random target gestures
- Live scoring system
- Helps users learn gesture language quickly

---

### ğŸ“œ Command Log
- Shows last detected commands
- Includes timestamp + confidence
- Only logs **gesture changes** (no spam)

---

### ğŸ¨ UI / UX
- Clean **Tailwind CSS** UI
- Live confidence bar
- Animated banners for critical actions
- Dev mode for debugging
- Works fully in browser (no frontend framework)

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|---|---|
| Vision | OpenCV, MediaPipe |
| Backend | Python, Flask |
| Frontend | HTML, Tailwind CSS, Vanilla JS |
| Voice | Web Speech API |
| Architecture | Real-time streaming (MJPEG) |

---

## ğŸ“‚ Project Structure

```yaml
Speak-Without-Words/
â”‚
â”œâ”€â”€ app.py                  # Flask backend
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ detector.py         # Hand detection (MediaPipe)
â”‚   â””â”€â”€ gestures.py         # Gesture classification logic
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html          # UI (Tailwind + JS)
â”‚
â”œâ”€â”€ static/
â”‚   â””â”€â”€ sounds.mp3          # (Optional) sound effect
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
````

---

# Speak-Without-Words

## âš™ï¸ Installation & Run

### 1ï¸âƒ£ Create environment
```bash
conda create -n speak-without-words python=3.11 -y
```
```bash
conda activate speak-without-words
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run the app
```bash
python app.py
```

### 3ï¸âƒ£ Open in browser

```bash
http://127.0.0.1:5000
```

---

## ğŸ¯ Use Cases

* Silent communication in noisy environments
* Accessibility tools for speech-impaired users
* Emergency signaling
* Humanâ€“computer interaction research
* Gesture-based UI systems

---

## ğŸ§ª How It Works (High Level)

1. Webcam captures frames
2. MediaPipe detects hand landmarks
3. Rule-based logic classifies gestures
4. Temporal smoothing stabilizes output
5. Gesture â†’ intent â†’ UI + voice feedback

---

## ğŸ† Hackathon Notes

* Built rapidly with focus on **clarity + usability**
* No heavy ML training required
* Runs fully on local machine
* Easy to demo and explain

---

## ğŸ”® Future Improvements

* Multi-user gesture detection
* Sign-language sentence building
* Mobile camera support
* Gesture personalization
* Cloud / IoT integrations

---

## ğŸ§‘â€ğŸ’» Author
**Shriful Islam** (InHuman)  

Built with â¤ï¸ by a university student exploring **Computer Vision, AI, and Human-Centered Design**.

---

## ğŸ“œ License

MIT License â€” free to use, modify, and extend.

